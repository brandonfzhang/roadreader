{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roadreader_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci5skbYt0QDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7rzmGf-33NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfbduE1mpdw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive #STU NAPERVILLE ACCOUNTS DON'T WORK - USE YOUR PERSONAL GOOGLE ACCOUNTS\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9J0x5k1CUKS",
        "colab_type": "code",
        "outputId": "43f47293-e06c-4fd0-f998-42c2fd389f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, brightness_range=(-1, 1))\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        \"/content/drive/My Drive/ROADREADER DATASETS/training\",\n",
        "        target_size=(300, 400),\n",
        "        batch_size=32, \n",
        "        color_mode=\"rgb\",\n",
        "        class_mode=\"sparse\",\n",
        "        shuffle=True)\n",
        "\n",
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, brightness_range=(-1, 1))\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        \"/content/drive/My Drive/ROADREADER DATASETS/tests\",\n",
        "        target_size=(300, 400),\n",
        "        batch_size=32, \n",
        "        color_mode=\"rgb\",\n",
        "        class_mode=\"sparse\",\n",
        "        shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1196 images belonging to 2 classes.\n",
            "Found 204 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKnKYVmD-2eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "  layers.Conv2D(14, 3, activation='relu', input_shape=(300,400,3)),\n",
        "  layers.MaxPooling2D((2,2), padding='same'),\n",
        "  layers.Conv2D(28, 3, activation='relu'),\n",
        "  layers.MaxPooling2D((2,2), padding='same'),\n",
        "  layers.Conv2D(42, 3, activation='relu'),\n",
        "  layers.MaxPooling2D((2,2), padding='same'),\n",
        "  layers.Conv2D(84, 3, activation='relu'),\n",
        "  layers.MaxPooling2D((2,2), padding='same'),\n",
        "  layers.Conv2D(84, 3, activation='relu'),\n",
        "  layers.MaxPooling2D((2,2), padding='same'),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(200, activation='relu'),\n",
        "  layers.Dense(2, activation='softmax'), #classification layer; 0 for none 1 for stop\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGyaLgMLA5Kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaBaozT4B7fn",
        "colab_type": "code",
        "outputId": "93fb3f0f-b8a3-4546-c6fc-7c27dbe119ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "source": [
        "#model.fit(x=train_images,y=train_labels, validation_data=(test_images, test_labels), epochs=10, batch_size=128)\n",
        "\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=64,\n",
        "        epochs=20,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=10,\n",
        "        workers=6,\n",
        "        use_multiprocessing=True\n",
        "        #max_queue_size=10\n",
        "        )\n",
        "\n",
        "'''\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=test_generator.n//test_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10\n",
        ")\n",
        "                    '''\n",
        "\n",
        "model.save_weights('/content/model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "64/64 [==============================] - 163s 3s/step - loss: 0.7148 - acc: 0.6290 - val_loss: 0.5236 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "64/64 [==============================] - 164s 3s/step - loss: 0.4828 - acc: 0.6992 - val_loss: 0.6197 - val_acc: 0.9000\n",
            "Epoch 3/20\n",
            "64/64 [==============================] - 164s 3s/step - loss: 0.4560 - acc: 0.7061 - val_loss: 0.1187 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "64/64 [==============================] - 158s 2s/step - loss: 0.4167 - acc: 0.7209 - val_loss: 0.6323 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "64/64 [==============================] - 163s 3s/step - loss: 0.4672 - acc: 0.6942 - val_loss: 0.9110 - val_acc: 0.0000e+00\n",
            "Epoch 6/20\n",
            "64/64 [==============================] - 164s 3s/step - loss: 0.4376 - acc: 0.7125 - val_loss: 0.7440 - val_acc: 0.0000e+00\n",
            "Epoch 7/20\n",
            "64/64 [==============================] - 156s 2s/step - loss: 0.4295 - acc: 0.7196 - val_loss: 0.8899 - val_acc: 0.0000e+00\n",
            "Epoch 8/20\n",
            "64/64 [==============================] - 164s 3s/step - loss: 0.4294 - acc: 0.7291 - val_loss: 0.4406 - val_acc: 0.4000\n",
            "Epoch 9/20\n",
            "64/64 [==============================] - 164s 3s/step - loss: 0.4440 - acc: 0.7160 - val_loss: 0.6737 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "64/64 [==============================] - 157s 2s/step - loss: 0.5538 - acc: 0.6798 - val_loss: 0.6873 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "64/64 [==============================] - 165s 3s/step - loss: 0.4145 - acc: 0.7239 - val_loss: 1.2039 - val_acc: 0.9000\n",
            "Epoch 12/20\n",
            "64/64 [==============================] - 164s 3s/step - loss: 0.3789 - acc: 0.7410 - val_loss: 0.2383 - val_acc: 0.9000\n",
            "Epoch 13/20\n",
            "64/64 [==============================] - 157s 2s/step - loss: 0.3848 - acc: 0.7485 - val_loss: 0.0741 - val_acc: 0.9000\n",
            "Epoch 14/20\n",
            "64/64 [==============================] - 164s 3s/step - loss: 0.3861 - acc: 0.7371 - val_loss: 0.2933 - val_acc: 0.6000\n",
            "Epoch 15/20\n",
            "64/64 [==============================] - 164s 3s/step - loss: 0.3703 - acc: 0.7539 - val_loss: 4.8170e-05 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "64/64 [==============================] - 156s 2s/step - loss: 0.3902 - acc: 0.7311 - val_loss: 0.7194 - val_acc: 0.0000e+00\n",
            "Epoch 17/20\n",
            "64/64 [==============================] - 165s 3s/step - loss: 0.3693 - acc: 0.7500 - val_loss: 0.2814 - val_acc: 0.6000\n",
            "Epoch 18/20\n",
            "64/64 [==============================] - 163s 3s/step - loss: 0.3819 - acc: 0.7414 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "64/64 [==============================] - 164s 3s/step - loss: 0.3770 - acc: 0.7322 - val_loss: 0.4376 - val_acc: 0.4000\n",
            "Epoch 20/20\n",
            "64/64 [==============================] - 161s 3s/step - loss: 0.3927 - acc: 0.7426 - val_loss: 0.0365 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}